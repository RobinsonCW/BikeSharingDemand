---
title: "Stats2Project1"
author: "Neha Dixit"
date: "9/23/2019"
output: html_document
---



## Introduction

The bike sharing system is a means of renting a bicycle via a network of kiosk locations throughout a city and returning it to a different place as needed.

For this analysis, we are looking at the two years worth of Capital Bikeshare program data from Washington D.C.The training set includes data for first 19 days of each month and test data set comprises of 20th day to the end of month data.

The objective is to predict the total count of bikes rented during each hour  covered by the test set.


## Exploratory Data Analysis

Exploratory Data Analysis is an approach to analysis the various characteristic of the data, often via visual methods.


```{r EDA}
# Load Libraries

library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot) 
library(ggthemes)
library(caret)
library(tidyverse)
library(gridExtra)
library(car)


# Load Source Training dataset

FileLocation <- ("C:/Users/ndixit/Documents/SMU/Sem2/Stats2/Project/BikeSharingDemand/anaylsis/data/train.csv")
Bike.Train <- read.csv(FileLocation)

FileLocation.Test <- ("C:/Users/ndixit/Documents/SMU/Sem2/Stats2/Project/BikeSharingDemand/anaylsis/data/test.csv")
Bike.Test<- read.csv(FileLocation.Test)

#Identify NA in dataset

Bike.Train.NA <- colSums(sapply(Bike.Train, is.na))
Bike.Train.NA <- data.frame(Variables = names(Bike.Train.NA), NA.Count = Bike.Train.NA); rownames(Bike.Train.NA) <- c()
Bike.Train.NA

# Identify Character variables

Bike.Train.List <- sapply(Bike.Train, class)
Bike.Train.List

#Identify unique values

Bike.Train.Unique <- rapply(Bike.Train,function(x)length(unique(x)))
Bike.Train.Unique <- data.frame(Variables = names(Bike.Train.Unique), Unique.Count = Bike.Train.Unique); rownames(Bike.Train.Unique) <- c()
Bike.Train.Unique

# Data visualizations
# Plot numerical variables correlation
# If the explanatory variables are highly associated with each other, regression coefficients can become unreliable and provide inconsistent interpretations.

correlator  <-  function(df){
	df %>% 	
		keep(is.numeric) %>%
		cor %>%
		corrplot( addCoef.col = "white", number.digits = 2,
			 number.cex = 0.5, method="circle",
			 order="hclust", title="Variable Corr Heatmap",
			 tl.srt=45, tl.cex = 0.8)
}
correlator(Bike.Train)


# Numerical data exploration
# We can ignore causal and registered user counts

p1 <- ggplot(Bike.Train) + geom_histogram(aes(temp), binwidth = 5, fill = "orange",col = "black")
p2 <- ggplot(Bike.Train) + geom_histogram(aes(atemp), binwidth = 5, fill = "orange",col = "black")
p3 <- ggplot(Bike.Train) + geom_histogram(aes(humidity), binwidth = 2, fill = "orange",col = "black")
p4 <- ggplot(Bike.Train) + geom_histogram(aes(windspeed), binwidth = 4, fill = "orange",col = "black")


grid.arrange(p1, p2, p3, p4, ncol = 3, nrow = 2)

p1 <- ggplot(Bike.Train,aes(x=temp, y=count)) + geom_point(col="orange") + geom_smooth(method="lm", col="blue") 
p2 <- ggplot(Bike.Train,aes(x=atemp, y=count)) + geom_point(col="orange") + geom_smooth(method="lm", col="blue") 
p3 <- ggplot(Bike.Train,aes(x=humidity, y=count)) + geom_point(col="orange") + geom_smooth(method="lm", col="blue") 
p4 <- ggplot(Bike.Train,aes(x=windspeed, y=count)) + geom_point(col="orange") + geom_smooth(method="lm", col="blue") 
p5<- ggplot(Bike.Train,aes(x=datetime, y=count)) + geom_point(col="orange") + geom_smooth(method="lm", col="blue") 

grid.arrange(p1, p2, p3, p4,p5 , ncol = 2, nrow = 3)

#categorial Data Exploration

# Count by Season
Bike.Train$season <- factor(Bike.Train$season)
Bike.Train.Season <- as.data.frame(Bike.Train%>% group_by(season) %>% summarise(count= sum(count)))
Bike.Train.Season %>% ggplot(aes(x = season, y = count) ) + xlab("season") + ylab("Counts") +geom_bar(stat="identity",  position="dodge", fill = "orange")

# Count by Holiday

Bike.Train$holiday <- factor(Bike.Train$holiday)
Bike.Train.Holiday <- as.data.frame(Bike.Train%>% group_by(holiday) %>% summarise(count= sum(count)))
Bike.Train.Holiday %>% ggplot(aes(x = holiday, y = count) ) + xlab("holiday") + ylab("Counts") +geom_bar(stat="identity",  position="dodge", fill = "orange")


# Count by workingday
Bike.Train$workingday <- factor(Bike.Train$workingday)
Bike.Train.WorkingDay <- as.data.frame(Bike.Train%>% group_by(workingday) %>% summarise(count= sum(count)))
Bike.Train.WorkingDay %>% ggplot(aes(x = workingday, y = count) ) + xlab("workingday") + ylab("Counts") +geom_bar(stat="identity",  position="dodge", fill = "orange")

# Count by weather

Bike.Train$weather <- factor(Bike.Train$weather)
Bike.Train.Weather <- as.data.frame(Bike.Train%>% group_by(weather) %>% summarise(count= sum(count)))
Bike.Train.Weather %>% ggplot(aes(x = weather, y = count) ) + xlab("weather") + ylab("Counts") +geom_bar(stat="identity",  position="dodge", fill = "orange")


# Summary Statistics 
summary(Bike.Train)
# For categorical explanatory variables it can be helpful to view summary statistics by each categorical level
t(aggregate(count~season,data=Bike.Train,summary))
t(aggregate(count~holiday,data=Bike.Train,summary))
t(aggregate(count~workingday,data=Bike.Train,summary))
t(aggregate(count~weather,data=Bike.Train,summary))


## Model selection

Bike.Train.Subset <- select(Bike.Train,-c("atemp","casual","registered"))
Bike.Test.Subset <- select(Bike.Test,-c("atemp"))

Bike.Train.Subset$date<- as.Date(Bike.Train.Subset$datetime)
Bike.Train.Subset$time<- format(as.POSIXct(Bike.Train.Subset$datetime) ,format = "%H:%M:%S") 
## splitting Dataset into training and test

Bike.Train.Subset <- select(Bike.Train.Subset,-c("datetime"))

set.seed(123)

 s_size <- function(df,split) {
	floor(nrow(df)*split)
}
sampler <- function(data, split, sn = 0){
	if (sn != 0) set.seed(sn)	
	train_ind <- sample(seq_len(nrow(data)), size = s_size(data, split))
	train <- data[train_ind,]
	test <- data[-train_ind, ]
	list("train" = train,  "test" = test)

}

partitions  <- sampler(data = Bike.Train.Subset, split = 0.75, sn = 0)
Training <- partitions$train
Test <- partitions$test
summary(Training)
summary(Test)

#a<- alias(lm(count~. , data= Training))
#vif(full.model)[,3]^2
#full.model<-lm(count~. , data= Training)
#vif(full.model)[,3]^2

Training.numeric <- Training%>% 	keep(is.numeric)
Test.numeric<- Test%>% 	keep(is.numeric)

Bike.Test.Subset$weather <- factor(Bike.Test.Subset$weather)
Bike.Test.Subset$workingday <- factor(Bike.Test.Subset$workingday)
Bike.Test.Subset$holiday <- factor(Bike.Test.Subset$holiday)
Bike.Test.Subset$season <- factor(Bike.Test.Subset$season)

Bike.Test.Subset.numeric <- Bike.Test.Subset%>% 	keep(is.numeric)

par(mfrow=c(1,3))
full.model<-lm(count~., data=Training)
vif(full.model)



lines(seq(30,300,.1),predict(full.model,newdata=Test.numeric),col="red",lwd=4)
plot(full.model$fitted.values,full.model$residuals,xlab="Fitted Values",ylab="Residuals")



#Forward Selection
library(leaps)
reg.fwd=regsubsets(log(count)~.,data=Training,method="forward",nvmax=10)

#backward Selection
reg.bkd=regsubsets(log(count)~.,data=Training,method="backward",nvmax=10)

#stepwise Selection
reg.stp=regsubsets(log(count)~.,data=Training,method="stepwise",nvmax=10)


#LASSO 
library(glmnet)
x=model.matrix(count~.,Training)[,-1]
y = log(Training$count)

xtest<-model.matrix(count~.,Test)[,-1]
ytest<-log(Test$count)

grid=10^seq(10,-2, length =100)
lasso.mod=glmnet(x,y,alpha=1, lambda =grid)

cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
plot(cv.out)

bestlambda<-cv.out$lambda.min  #Optimal penalty parameter. 
lasso.pred=predict (lasso.mod ,s=bestlambda ,newx=xtest)

testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO

coef(lasso.mod,s=bestlambda)



```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
